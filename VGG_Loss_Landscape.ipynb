{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm as tqdm\n",
    "from IPython import display\n",
    "\n",
    "from models.vgg import VGG_A\n",
    "from models.vgg import VGG_A_BatchNorm\n",
    "from data.loaders import get_cifar_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constants (parameters) initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "# add our package dir to path\n",
    "module_path = os.path.dirname(os.getcwd())\n",
    "home_path = module_path\n",
    "figures_path = os.path.join(home_path, 'reports', 'figures')\n",
    "models_path = os.path.join(home_path, 'reports', 'models')\n",
    "# Make sure you are using the right device.\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print(torch.cuda.get_device_name(0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Initialize your data loader and\n",
    "# make sure that dataloader works\n",
    "# as expected by observing one\n",
    "# sample from it.\n",
    "train_loader = get_cifar_loader(train=True)\n",
    "val_loader = get_cifar_loader(train=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# This function is used to calculate the accuracy of model classification\n",
    "def get_accuracy(dataloader, model, loss_fn):\n",
    "    ## --------------------\n",
    "    # Add code as needed\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X.to(device)).to(device)\n",
    "            test_loss += loss_fn(pred, y.to(device)).item()\n",
    "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Set a random seed to ensure reproducible results\n",
    "def set_random_seeds(seed_value=0, device='cpu'):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    if device != 'cpu':\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# We use this function to complete the entire\n",
    "# training process. In order to plot the loss landscape,\n",
    "# you need to record the loss value of each step.\n",
    "# Of course, as before, you can test your model\n",
    "# after drawing a training round and save the curve\n",
    "# to observe the training\n",
    "def train(model, optimizer, criterion, train_loader, val_loader, scheduler=None, epochs_n=100, best_model_path=None):\n",
    "    model.to(device)\n",
    "    learning_curve = [np.nan] * epochs_n\n",
    "    train_accuracy_curve = [np.nan] * epochs_n\n",
    "    val_accuracy_curve = [np.nan] * epochs_n\n",
    "    max_val_accuracy = 0\n",
    "    max_val_accuracy_epoch = 0\n",
    "\n",
    "    batches_n = len(train_loader)\n",
    "    losses_list = []\n",
    "    for epoch in tqdm(range(epochs_n), unit='epoch'):\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        model.train()\n",
    "\n",
    "        loss_list = []  # use this to record the loss value of each step\n",
    "        grad = []  # use this to record the loss gradient of each step\n",
    "        learning_curve[epoch] = 0  # maintain this to plot the training curve\n",
    "\n",
    "        for data in train_loader:\n",
    "            x, y = data\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(x)\n",
    "            loss = criterion(prediction, y)\n",
    "            # You may need to record some variable values here\n",
    "            # if you want to get loss gradient, use\n",
    "            # grad = model.classifier[4].weight.grad.clone()\n",
    "            ## --------------------\n",
    "            # Add your code\n",
    "            loss_list.append(loss.item())\n",
    "            # if model.classifier[4].weight.grad is not None:\n",
    "            #     loss_grad = model.classifier[4].weight.grad.clone().cpu()\n",
    "            #     grad.append(loss_grad)\n",
    "\n",
    "            ## --------------------\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses_list.append(loss_list)\n",
    "        display.clear_output(wait=True)\n",
    "        f, axes = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "        learning_curve[epoch] /= batches_n\n",
    "        axes[0].plot(learning_curve)\n",
    "\n",
    "        # Test your model and save figure here (not required)\n",
    "        # remember to use model.eval()\n",
    "        ## --------------------\n",
    "        # Add code as needed\n",
    "        model.eval()\n",
    "        cur_val_loss, cur_val_accuracy = get_accuracy(dataloader=val_loader, model=model, loss_fn=criterion)\n",
    "        max_val_accuracy = max(max_val_accuracy, cur_val_accuracy)\n",
    "        if max_val_accuracy == cur_val_accuracy:\n",
    "            max_val_accuracy_epoch = epoch\n",
    "\n",
    "        ## --------------------\n",
    "\n",
    "    losses_list = losses_list + loss_list\n",
    "    return losses_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:35<00:00, 43.10s/epoch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 74.8%, Avg loss: 0.006106 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train your model\n",
    "# feel free to modify\n",
    "epo = 5\n",
    "loss_save_path = ''\n",
    "grad_save_path = ''\n",
    "\n",
    "set_random_seeds(seed_value=2020, device=device)\n",
    "lr_list = [0.001, 0.002, 0.0001, 0.0005]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = []\n",
    "grads = []\n",
    "for idx in range(len(lr_list)):\n",
    "    model = VGG_A_BatchNorm()\n",
    "    model._init_weights()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_list[idx])\n",
    "    loss_single_lr = train(model, optimizer, criterion, train_loader, val_loader, epochs_n=epo)\n",
    "    np.savetxt(os.path.join(loss_save_path, 'loss' + str(idx) +'withBN.txt'), loss_single_lr, fmt='%s', delimiter=' ')\n",
    "\n",
    "for idx in range(len(lr_list)):\n",
    "    model = VGG_A()\n",
    "    model._init_weights()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_list[idx])\n",
    "    loss_single_lr = train(model, optimizer, criterion, train_loader, val_loader, epochs_n=epo)\n",
    "    np.savetxt(os.path.join(loss_save_path, 'loss' + str(idx) +'.txt'), loss_single_lr, fmt='%s', delimiter=' ')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "loss_lr0 = np.loadtxt(f'loss0.txt', delimiter=',')\n",
    "loss_lr1 = np.loadtxt(f'loss1.txt', delimiter=',')\n",
    "loss_lr2 = np.loadtxt(f'loss2.txt', delimiter=',')\n",
    "loss_lr3 = np.loadtxt(f'loss3.txt', delimiter=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "loss_lr0_bn = np.loadtxt(f'loss0withBN.txt', delimiter=',')\n",
    "loss_lr1_bn = np.loadtxt(f'loss1withBN.txt', delimiter=',')\n",
    "loss_lr2_bn = np.loadtxt(f'loss2withBN.txt', delimiter=',')\n",
    "loss_lr3_bn = np.loadtxt(f'loss3withBN.txt', delimiter=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "mpl.use('tkagg')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(1955,)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_lr0.reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "loss_lr0 = loss_lr0.reshape(-1)\n",
    "loss_lr1 = loss_lr1.reshape(-1)\n",
    "loss_lr2 = loss_lr2.reshape(-1)\n",
    "loss_lr3 = loss_lr3.reshape(-1)\n",
    "loss_lr0_bn = loss_lr0_bn.reshape(-1)\n",
    "loss_lr1_bn = loss_lr1_bn.reshape(-1)\n",
    "loss_lr2_bn = loss_lr2_bn.reshape(-1)\n",
    "loss_lr3_bn = loss_lr3_bn.reshape(-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "max_curve, min_curve = [], []\n",
    "max_curve_bn, min_curve_bn = [], []\n",
    "for i in range(len(loss_lr0)):\n",
    "    max_curve.append(max(loss_lr0[i], loss_lr1[i], loss_lr2[i], loss_lr3[i]))\n",
    "    min_curve.append(min(loss_lr0[i], loss_lr1[i], loss_lr2[i], loss_lr3[i]))\n",
    "    max_curve_bn.append(max(loss_lr0_bn[i], loss_lr1_bn[i], loss_lr2_bn[i], loss_lr3_bn[i]))\n",
    "    min_curve_bn.append(min(loss_lr0_bn[i], loss_lr1_bn[i], loss_lr2_bn[i], loss_lr3_bn[i]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "plt.fill_between(x=np.arange(0, 1955), y1=max_curve, y2=min_curve, label='without BN')\n",
    "plt.fill_between(x=np.arange(0, 1955), y1=max_curve_bn, y2=min_curve_bn, label='with BN')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}